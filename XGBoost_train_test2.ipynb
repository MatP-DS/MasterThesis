{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ6PWlsonX4aiA6ZYm0w//",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatP-DS/MasterThesis/blob/main/XGBoost_train_test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i44c-Jt5yqW"
      },
      "outputs": [],
      "source": [
        "# Load data again after kernel reset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from collections import Counter\n",
        "import time\n",
        "import xgboost as xgb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load from Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "X = np.load(\"/content/drive/MyDrive/MasterThesis/02_preprocessed_data/X_flattened_final.npz\")[\"X\"]\n",
        "y = np.load(\"/content/drive/MyDrive/MasterThesis/02_preprocessed_data/y_labels_final.npz\")[\"y\"]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6SOWHtH58-0",
        "outputId": "6c0da145-50d5-4d01-c03c-ec9b2d3acaea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/test split with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Compute scale_pos_weight to handle imbalance\n",
        "class_counts = Counter(y_train)\n",
        "scale = class_counts[0] / class_counts[1]\n"
      ],
      "metadata": {
        "id": "_c7vFAkj6LRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and train XGBoost model\n",
        "model = xgb.XGBClassifier(\n",
        "    objective=\"binary:logistic\",\n",
        "    scale_pos_weight=scale,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    n_estimators=100,\n",
        "    n_jobs=-1,\n",
        "    verbosity=0,\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "model.fit(X_train, y_train)\n",
        "train_time = time.time() - start\n"
      ],
      "metadata": {
        "id": "LlFyza0f6NBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "metrics = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"F1 (loss)\": f1_score(y_test, y_pred, pos_label=1),\n",
        "    \"Recall (loss)\": recall_score(y_test, y_pred, pos_label=1),\n",
        "    \"Precision (loss)\": precision_score(y_test, y_pred, pos_label=1),\n",
        "    \"Training Time (s)\": train_time\n",
        "}\n"
      ],
      "metadata": {
        "id": "7qpb-Cy_6RI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm, index=[\"No Loss (0)\", \"Loss (1)\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
        "metrics_df = pd.DataFrame([metrics])\n",
        "\n",
        "metrics_df, cm_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qPqnCCX6Sox",
        "outputId": "80f6c3ca-3cfe-497a-ba84-c7db31e62ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   Accuracy  F1 (loss)  Recall (loss)  Precision (loss)  Training Time (s)\n",
              " 0  0.999647   0.891967        0.94152          0.847368         200.007808,\n",
              "              Predicted 0  Predicted 1\n",
              " No Loss (0)       110210           29\n",
              " Loss (1)              10          161)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save metrics_df from your evaluation\n",
        "metrics_df.to_csv('/content/drive/MyDrive/MasterThesis/04_results/metrics/xgboost_metrics.csv', index=False)\n",
        "\n",
        "\n",
        "# Confusion matrix (optional)\n",
        "cm_df.to_csv('/content/drive/MyDrive/MasterThesis/04_results/metrics/xgboost_confusion_matrix.csv')\n"
      ],
      "metadata": {
        "id": "e-hnDbYO8QYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_results_extended(model_name, model, metrics_df, cm_df=None, folder=\"/content/drive/MyDrive/MasterThesis/04_results/metrics\"):\n",
        "    \"\"\"\n",
        "    Save model evaluation results including metrics, hyperparameters, and confusion matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - model_name: str, name of the model (e.g., \"xgboost\", \"random_forest\")\n",
        "    - model: trained model object with `.get_params()` or `.__dict__`\n",
        "    - metrics_df: pd.DataFrame with one row of evaluation metrics\n",
        "    - cm_df: pd.DataFrame with confusion matrix (optional)\n",
        "    - folder: target folder path\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import json\n",
        "    from datetime import datetime\n",
        "\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    # Timestamp for versioned output\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    base_filename = f\"{model_name}_metrics_{timestamp}\"\n",
        "\n",
        "    # Save metrics CSV and JSON\n",
        "    metrics_path_csv = os.path.join(folder, f\"{base_filename}.csv\")\n",
        "    metrics_df.to_csv(metrics_path_csv, index=False)\n",
        "\n",
        "    # Extract model parameters\n",
        "    try:\n",
        "        params = model.get_params()\n",
        "    except AttributeError:\n",
        "        # fallback for native lightgbm or xgboost booster objects\n",
        "        params = model.__dict__\n",
        "\n",
        "    # Combine everything into one JSON log\n",
        "    log_dict = {\n",
        "        \"model_name\": model_name,\n",
        "        \"timestamp\": timestamp,\n",
        "        \"metrics\": metrics_df.to_dict(orient=\"records\")[0],\n",
        "        \"hyperparameters\": {k: str(v) for k, v in params.items()}\n",
        "    }\n",
        "\n",
        "    # Save full metadata log as JSON\n",
        "    metrics_path_json = os.path.join(folder, f\"{base_filename}.json\")\n",
        "    with open(metrics_path_json, 'w') as f:\n",
        "        json.dump(log_dict, f, indent=4)\n",
        "\n",
        "    # Save confusion matrix separately if given\n",
        "    cm_path_csv = None\n",
        "    if cm_df is not None:\n",
        "        cm_path_csv = os.path.join(folder, f\"{base_filename}_confusion_matrix.csv\")\n",
        "        cm_df.to_csv(cm_path_csv)\n",
        "\n",
        "    return {\n",
        "        \"csv\": metrics_path_csv,\n",
        "        \"json\": metrics_path_json,\n",
        "        \"confusion_matrix\": cm_path_csv\n",
        "    }\n"
      ],
      "metadata": {
        "id": "cWyWAUHm-bzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_results_extended(model_name, model, metrics_df, cm_df=None,\n",
        "                              folder=\"/content/drive/MyDrive/MasterThesis/04_results/metrics\"):\n",
        "    \"\"\"\n",
        "    Enhanced logging function that aligns with research questions while maintaining compatibility\n",
        "    with your existing code structure.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import json\n",
        "    from datetime import datetime\n",
        "    import psutil\n",
        "    import timeit\n",
        "    import pickle\n",
        "\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # Convert confusion matrix if provided\n",
        "    cm_dict = None\n",
        "    if cm_df is not None:\n",
        "        cm_dict = {\n",
        "            \"columns\": cm_df.columns.tolist(),\n",
        "            \"data\": cm_df.values.tolist()\n",
        "        }\n",
        "\n",
        "    # Get basic system metrics (will work even without GPU)\n",
        "    cpu_usage = psutil.cpu_percent()\n",
        "    ram_used = psutil.virtual_memory().used / (1024**3)  # GB\n",
        "\n",
        "    try:\n",
        "        import GPUtil\n",
        "        gpu_usage = GPUtil.getGPUs()[0].load if GPUtil.getGPUs() else None\n",
        "    except:\n",
        "        gpu_usage = None\n",
        "\n",
        "    # Create the comprehensive log dictionary\n",
        "    log_dict = {\n",
        "        \"model\": model_name,\n",
        "        \"timestamp\": timestamp,\n",
        "        \"metrics\": {\n",
        "            \"accuracy\": float(metrics_df[\"Accuracy\"].iloc[0]),\n",
        "            \"f1_loss\": float(metrics_df[\"F1 (loss)\"].iloc[0]),\n",
        "            \"recall_loss\": float(metrics_df[\"Recall (loss)\"].iloc[0]),\n",
        "            \"precision_loss\": float(metrics_df[\"Precision (loss)\"].iloc[0]),\n",
        "            \"training_time_s\": float(metrics_df[\"Training Time (s)\"].iloc[0])\n",
        "        },\n",
        "        \"confusion_matrix\": cm_dict,\n",
        "        \"system_metrics\": {\n",
        "            \"cpu_usage_percent\": cpu_usage,\n",
        "            \"ram_used_gb\": ram_used,\n",
        "            \"gpu_usage\": gpu_usage\n",
        "        },\n",
        "        \"hyperparameters\": {k: str(v) for k, v in model.get_params().items()}\n",
        "    }\n",
        "\n",
        "    # Save JSON log\n",
        "    json_path = os.path.join(folder, f\"{model_name}_metrics_{timestamp}.json\")\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(log_dict, f, indent=4)\n",
        "\n",
        "    # Maintain your original CSV outputs for compatibility\n",
        "    csv_path = os.path.join(folder, f\"{model_name}_metrics_{timestamp}.csv\")\n",
        "    metrics_df.to_csv(csv_path, index=False)\n",
        "\n",
        "    if cm_df is not None:\n",
        "        cm_path = os.path.join(folder, f\"{model_name}_confusion_matrix_{timestamp}.csv\")\n",
        "        cm_df.to_csv(cm_path)\n",
        "\n",
        "    return {\n",
        "        \"json_path\": json_path,\n",
        "        \"csv_path\": csv_path,\n",
        "        \"cm_path\": cm_path if cm_df is not None else None\n",
        "    }"
      ],
      "metadata": {
        "id": "fCv7IIgykIrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your existing code remains unchanged:\n",
        "results = save_model_results_extended(\"xgboost\", model, metrics_df, cm_df)\n"
      ],
      "metadata": {
        "id": "GqMYdMvX-hml"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}